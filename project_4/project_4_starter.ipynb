{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import project_tests\n",
    "import project_helper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import project_helper\n",
    "from zipline.data import bundles\n",
    "\n",
    "os.environ['ZIPLINE_ROOT'] = os.path.join(os.getcwd(), '..', '..', 'data', 'project_4_eod')\n",
    "\n",
    "ingest_func = bundles.csvdir.csvdir_equities(['daily'], project_helper.EOD_BUNDLE_NAME)\n",
    "bundles.register(project_helper.EOD_BUNDLE_NAME, ingest_func)\n",
    "\n",
    "print('Data Registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import AverageDollarVolume\n",
    "from zipline.utils.calendars import get_calendar\n",
    "\n",
    "\n",
    "universe = AverageDollarVolume(window_length=120).top(500) \n",
    "trading_calendar = get_calendar('NYSE') \n",
    "bundle_data = bundles.load(project_helper.EOD_BUNDLE_NAME)\n",
    "engine = project_helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_end_date = pd.Timestamp('2016-01-05', tz='UTC')\n",
    "\n",
    "universe_tickers = engine\\\n",
    "    .run_pipeline(\n",
    "        Pipeline(screen=universe),\n",
    "        universe_end_date,\n",
    "        universe_end_date)\\\n",
    "    .index.get_level_values(1)\\\n",
    "    .values.tolist()\n",
    "    \n",
    "universe_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "\n",
    "data_portal = DataPortal(\n",
    "    bundle_data.asset_finder,\n",
    "    trading_calendar=trading_calendar,\n",
    "    first_trading_day=bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "    equity_minute_reader=None,\n",
    "    equity_daily_reader=bundle_data.equity_daily_bar_reader,\n",
    "    adjustment_reader=bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pricing(data_portal, trading_calendar, assets, start_date, end_date, field='close'):\n",
    "    end_dt = pd.Timestamp(end_date.strftime('%Y-%m-%d'), tz='UTC', offset='C')\n",
    "    start_dt = pd.Timestamp(start_date.strftime('%Y-%m-%d'), tz='UTC', offset='C')\n",
    "\n",
    "    end_loc = trading_calendar.closes.index.get_loc(end_dt)\n",
    "    start_loc = trading_calendar.closes.index.get_loc(start_dt)\n",
    "\n",
    "    return data_portal.get_history_window(\n",
    "        assets=assets,\n",
    "        end_dt=end_dt,\n",
    "        bar_count=end_loc - start_loc,\n",
    "        frequency='1d',\n",
    "        field=field,\n",
    "        data_frequency='daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_year_returns = \\\n",
    "    get_pricing(\n",
    "        data_portal,\n",
    "        trading_calendar,\n",
    "        universe_tickers,\n",
    "        universe_end_date - pd.DateOffset(years=5),\n",
    "        universe_end_date)\\\n",
    "    .pct_change()[1:].fillna(0)\n",
    "\n",
    "five_year_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def fit_pca(returns, num_factor_exposures, svd_solver):\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_fit_pca(fit_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factor_exposures = 20\n",
    "pca = fit_pca(five_year_returns, num_factor_exposures, 'full')\n",
    "\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(num_factor_exposures), pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_betas(pca, factor_beta_indices, factor_beta_columns):\n",
    "\n",
    "    assert len(factor_beta_indices.shape) == 1\n",
    "    assert len(factor_beta_columns.shape) == 1\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_factor_betas(factor_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model = {}\n",
    "risk_model['factor_betas'] = factor_betas(pca, five_year_returns.columns.values, np.arange(num_factor_exposures))\n",
    "\n",
    "risk_model['factor_betas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_returns(pca, returns, factor_return_indices, factor_return_columns):\n",
    "\n",
    "    assert len(factor_return_indices.shape) == 1\n",
    "    assert len(factor_return_columns.shape) == 1\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_factor_returns(factor_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model['factor_returns'] = factor_returns(\n",
    "    pca,\n",
    "    five_year_returns,\n",
    "    five_year_returns.index,\n",
    "    np.arange(num_factor_exposures))\n",
    "\n",
    "risk_model['factor_returns'].cumsum().plot(legend=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_cov_matrix(factor_returns, ann_factor):\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_factor_cov_matrix(factor_cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_factor = 252\n",
    "risk_model['factor_cov_matrix'] = factor_cov_matrix(risk_model['factor_returns'], ann_factor)\n",
    "\n",
    "risk_model['factor_cov_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiosyncratic_var_matrix(returns, factor_returns, factor_betas, ann_factor):\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_idiosyncratic_var_matrix(idiosyncratic_var_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model['idiosyncratic_var_matrix'] = idiosyncratic_var_matrix(five_year_returns, risk_model['factor_returns'], risk_model['factor_betas'], ann_factor)\n",
    "\n",
    "risk_model['idiosyncratic_var_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiosyncratic_var_vector(returns, idiosyncratic_var_matrix):\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_idiosyncratic_var_vector(idiosyncratic_var_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model['idiosyncratic_var_vector'] = idiosyncratic_var_vector(five_year_returns, risk_model['idiosyncratic_var_matrix'])\n",
    "\n",
    "risk_model['idiosyncratic_var_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_portfolio_risk(factor_betas, factor_cov_matrix, idiosyncratic_var_matrix, weights):\n",
    "\n",
    "    assert len(factor_cov_matrix.shape) == 2\n",
    "    \n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_predict_portfolio_risk(predict_portfolio_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = pd.DataFrame(np.repeat(1/len(universe_tickers), len(universe_tickers)), universe_tickers)\n",
    "\n",
    "predict_portfolio_risk(\n",
    "    risk_model['factor_betas'],\n",
    "    risk_model['factor_cov_matrix'],\n",
    "    risk_model['idiosyncratic_var_matrix'],\n",
    "    all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.factors import Returns\n",
    "\n",
    "def momentum_1yr(window_length, universe, sector):\n",
    "    return Returns(window_length=window_length, mask=universe) \\\n",
    "        .demean(groupby=sector) \\\n",
    "        .rank() \\\n",
    "        .zscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reversion_5day_sector_neutral(window_length, universe, sector):\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_mean_reversion_5day_sector_neutral(mean_reversion_5day_sector_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_start_date = universe_end_date - pd.DateOffset(years=2, days=2)\n",
    "sector = project_helper.Sector()\n",
    "window_length = 5\n",
    "\n",
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral(window_length, universe, sector),\n",
    "    'Mean_Reversion_5Day_Sector_Neutral')\n",
    "engine.run_pipeline(pipeline, factor_start_date, universe_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.factors import SimpleMovingAverage\n",
    "\n",
    "def mean_reversion_5day_sector_neutral_smoothed(window_length, universe, sector):\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_mean_reversion_5day_sector_neutral_smoothed(mean_reversion_5day_sector_neutral_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral_smoothed(5, universe, sector),\n",
    "    'Mean_Reversion_5Day_Sector_Neutral_Smoothed')\n",
    "engine.run_pipeline(pipeline, factor_start_date, universe_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.data import USEquityPricing\n",
    "\n",
    "\n",
    "class CTO(Returns):\n",
    "    \"\"\"\n",
    "    Computes the overnight return, per hypothesis from\n",
    "    https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2554010\n",
    "    \"\"\"\n",
    "    inputs = [USEquityPricing.open, USEquityPricing.close]\n",
    "    \n",
    "    def compute(self, today, assets, out, opens, closes):\n",
    "        \"\"\"\n",
    "        The opens and closes matrix is 2 rows x N assets, with the most recent at the bottom.\n",
    "        As such, opens[-1] is the most recent open, and closes[0] is the earlier close\n",
    "        \"\"\"\n",
    "        out[:] = (opens[-1] - closes[0]) / closes[0]\n",
    "\n",
    "        \n",
    "class TrailingOvernightReturns(Returns):\n",
    "    \"\"\"\n",
    "    Sum of trailing 1m O/N returns\n",
    "    \"\"\"\n",
    "    window_safe = True\n",
    "    \n",
    "    def compute(self, today, asset_ids, out, cto):\n",
    "        out[:] = np.nansum(cto, axis=0)\n",
    "\n",
    "        \n",
    "def overnight_sentiment(cto_window_length, trail_overnight_returns_window_length, universe):\n",
    "    cto_out = CTO(mask=universe, window_length=cto_window_length)\n",
    "    return TrailingOvernightReturns(inputs=[cto_out], window_length=trail_overnight_returns_window_length) \\\n",
    "        .rank() \\\n",
    "        .zscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overnight_sentiment_smoothed(cto_window_length, trail_overnight_returns_window_length, universe):\n",
    "    unsmoothed_factor = overnight_sentiment(cto_window_length, trail_overnight_returns_window_length, universe)\n",
    "    return SimpleMovingAverage(inputs=[unsmoothed_factor], window_length=trail_overnight_returns_window_length) \\\n",
    "        .rank() \\\n",
    "        .zscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = AverageDollarVolume(window_length=120).top(500)\n",
    "sector = project_helper.Sector()\n",
    "\n",
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline.add(\n",
    "    momentum_1yr(252, universe, sector),\n",
    "    'Momentum_1YR')\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral(5, universe, sector),\n",
    "    'Mean_Reversion_5Day_Sector_Neutral')\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral_smoothed(5, universe, sector),\n",
    "    'Mean_Reversion_5Day_Sector_Neutral_Smoothed')\n",
    "pipeline.add(\n",
    "    overnight_sentiment(2, 5, universe),\n",
    "    'Overnight_Sentiment')\n",
    "pipeline.add(\n",
    "    overnight_sentiment_smoothed(2, 5, universe),\n",
    "    'Overnight_Sentiment_Smoothed')\n",
    "all_factors = engine.run_pipeline(pipeline, factor_start_date, universe_end_date)\n",
    "\n",
    "all_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphalens as al\n",
    "\n",
    "assets = all_factors.index.levels[1].values.tolist()\n",
    "pricing = get_pricing(\n",
    "    data_portal,\n",
    "    trading_calendar,\n",
    "    assets,\n",
    "    factor_start_date,\n",
    "    universe_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_factor_data = {\n",
    "    factor: al.utils.get_clean_factor_and_forward_returns(factor=factor_data, prices=pricing, periods=[1])\n",
    "    for factor, factor_data in all_factors.iteritems()}\n",
    "\n",
    "unixt_factor_data = {\n",
    "    factor: factor_data.set_index(pd.MultiIndex.from_tuples(\n",
    "        [(x.timestamp(), y) for x, y in factor_data.index.values],\n",
    "        names=['date', 'asset']))\n",
    "    for factor, factor_data in clean_factor_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_factor_returns = pd.DataFrame()\n",
    "\n",
    "for factor, factor_data in clean_factor_data.items():\n",
    "    ls_factor_returns[factor] = al.performance.factor_returns(factor_data).iloc[:, 0]\n",
    "\n",
    "(1+ls_factor_returns).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_factor_returns = pd.DataFrame()\n",
    "\n",
    "for factor, factor_data in unixt_factor_data.items():\n",
    "    qr_factor_returns[factor] = al.performance.mean_return_by_quantile(factor_data)[0].iloc[:, 0]\n",
    "\n",
    "(10000*qr_factor_returns).plot.bar(\n",
    "    subplots=True,\n",
    "    sharey=True,\n",
    "    layout=(4,2),\n",
    "    figsize=(14, 14),\n",
    "    legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_FRA = pd.DataFrame()\n",
    "\n",
    "for factor, factor_data in unixt_factor_data.items():\n",
    "    ls_FRA[factor] = al.performance.factor_rank_autocorrelation(factor_data)\n",
    "\n",
    "ls_FRA.plot(title=\"Factor Rank Autocorrelation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(factor_returns, annualization_factor):\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_sharpe_ratio(sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_annualization_factor = np.sqrt(252)\n",
    "sharpe_ratio(ls_factor_returns, daily_annualization_factor).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_factors = all_factors.columns[[1, 2, 4]]\n",
    "print('Selected Factors: {}'.format(', '.join(selected_factors)))\n",
    "\n",
    "all_factors['alpha_vector'] = all_factors[selected_factors].mean(axis=1)\n",
    "alphas = all_factors[['alpha_vector']]\n",
    "alpha_vector = alphas.loc[all_factors.index.get_level_values(0)[-1]]\n",
    "alpha_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class AbstractOptimalHoldings(ABC):    \n",
    "    @abstractmethod\n",
    "    def _get_obj(self, weights, alpha_vector):\n",
    "\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_constraints(self, weights, factor_betas, risk):\n",
    "\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _get_risk(self, weights, factor_betas, alpha_vector_index, factor_cov_matrix, idiosyncratic_var_vector):\n",
    "        f = factor_betas.loc[alpha_vector_index].values.T * weights\n",
    "        X = factor_cov_matrix\n",
    "        S = np.diag(idiosyncratic_var_vector.loc[alpha_vector_index].values.flatten())\n",
    "\n",
    "        return cvx.quad_form(f, X) + cvx.quad_form(weights, S)\n",
    "    \n",
    "    def find(self, alpha_vector, factor_betas, factor_cov_matrix, idiosyncratic_var_vector):\n",
    "        weights = cvx.Variable(len(alpha_vector))\n",
    "        risk = self._get_risk(weights, factor_betas, alpha_vector.index, factor_cov_matrix, idiosyncratic_var_vector)\n",
    "        \n",
    "        obj = self._get_obj(weights, alpha_vector)\n",
    "        constraints = self._get_constraints(weights, factor_betas.loc[alpha_vector.index].values, risk)\n",
    "        \n",
    "        prob = cvx.Problem(obj, constraints)\n",
    "        prob.solve(max_iters=500)\n",
    "\n",
    "        optimal_weights = np.asarray(weights.value).flatten()\n",
    "        \n",
    "        return pd.DataFrame(data=optimal_weights, index=alpha_vector.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalHoldings(AbstractOptimalHoldings):\n",
    "    def _get_obj(self, weights, alpha_vector):\n",
    "\n",
    "        assert(len(alpha_vector.columns) == 1)\n",
    "\n",
    "\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _get_constraints(self, weights, factor_betas, risk):\n",
    "\n",
    "        assert(len(factor_betas.shape) == 2)\n",
    "        \n",
    " \n",
    "        \n",
    "        return None\n",
    "\n",
    "    def __init__(self, risk_cap=0.05, factor_max=10.0, factor_min=-10.0, weights_max=0.55, weights_min=-0.55):\n",
    "        self.risk_cap=risk_cap\n",
    "        self.factor_max=factor_max\n",
    "        self.factor_min=factor_min\n",
    "        self.weights_max=weights_max\n",
    "        self.weights_min=weights_min\n",
    "\n",
    "\n",
    "project_tests.test_optimal_holdings_get_obj(OptimalHoldings)\n",
    "project_tests.test_optimal_holdings_get_constraints(OptimalHoldings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights = OptimalHoldings().find(alpha_vector, risk_model['factor_betas'], risk_model['factor_cov_matrix'], risk_model['idiosyncratic_var_vector'])\n",
    "\n",
    "optimal_weights.plot.bar(legend=None, title='Portfolio % Holdings by Stock')\n",
    "x_axis = plt.axes().get_xaxis()\n",
    "x_axis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_helper.get_factor_exposures(risk_model['factor_betas'], optimal_weights).plot.bar(\n",
    "    title='Portfolio Net Factor Exposures',\n",
    "    legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalHoldingsRegualization(OptimalHoldings):\n",
    "    def _get_obj(self, weights, alpha_vector):\n",
    "\n",
    "        assert(len(alpha_vector.columns) == 1)\n",
    "        \n",
    "\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def __init__(self, lambda_reg=0.5, risk_cap=0.05, factor_max=10.0, factor_min=-10.0, weights_max=0.55, weights_min=-0.55):\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.risk_cap=risk_cap\n",
    "        self.factor_max=factor_max\n",
    "        self.factor_min=factor_min\n",
    "        self.weights_max=weights_max\n",
    "        self.weights_min=weights_min\n",
    "        \n",
    "\n",
    "project_tests.test_optimal_holdings_regualization_get_obj(OptimalHoldingsRegualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights_1 = OptimalHoldingsRegualization(lambda_reg=5.0).find(alpha_vector, risk_model['factor_betas'], risk_model['factor_cov_matrix'], risk_model['idiosyncratic_var_vector'])\n",
    "\n",
    "optimal_weights_1.plot.bar(legend=None, title='Portfolio % Holdings by Stock')\n",
    "x_axis = plt.axes().get_xaxis()\n",
    "x_axis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_helper.get_factor_exposures(risk_model['factor_betas'], optimal_weights_1).plot.bar(\n",
    "    title='Portfolio Net Factor Exposures',\n",
    "    legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalHoldingsStrictFactor(OptimalHoldings):\n",
    "    def _get_obj(self, weights, alpha_vector):\n",
    "\n",
    "        assert(len(alpha_vector.columns) == 1)\n",
    "        \n",
    "\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "project_tests.test_optimal_holdings_strict_factor_get_obj(OptimalHoldingsStrictFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights_2 = OptimalHoldingsStrictFactor(\n",
    "    weights_max=0.02,\n",
    "    weights_min=-0.02,\n",
    "    risk_cap=0.0015,\n",
    "    factor_max=0.015,\n",
    "    factor_min=-0.015).find(alpha_vector, risk_model['factor_betas'], risk_model['factor_cov_matrix'], risk_model['idiosyncratic_var_vector'])\n",
    "\n",
    "optimal_weights_2.plot.bar(legend=None, title='Portfolio % Holdings by Stock')\n",
    "x_axis = plt.axes().get_xaxis()\n",
    "x_axis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_helper.get_factor_exposures(risk_model['factor_betas'], optimal_weights_2).plot.bar(\n",
    "    title='Portfolio Net Factor Exposures',\n",
    "    legend=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
